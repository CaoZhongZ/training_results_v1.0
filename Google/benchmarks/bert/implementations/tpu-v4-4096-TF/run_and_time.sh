for i in {1..1}; do python3 run_pretraining.py --bert_config_file=${INTERNAL_PATH} --beta_1=0.7206 --beta_2=0.78921 --nobinarylog --${INTERNAL}_job_name=coordinator --${INTERNAL}_jobs="tpu_worker|${INTERNAL_PATH} --${INTERNAL}_num_eigen_threads=200 --${INTERNAL}_num_operation_threads=200 --${INTERNAL}_port=14001 --${INTERNAL}_rpc_layer=rpc2 --no${INTERNAL}_run_locally --${INTERNAL}_session_gc_seconds=86400 --${INTERNAL}_task=0 --census_cpu_accounting_enabled --noclip_by_global_norm_after_grad --nodo_eval --do_train --enable_profiling --eval_batch_size=6144 --eval_input_file="/readahead/128M${INTERNAL_PATH} --gfs_user=tpu-perf-team --init_checkpoint=/readahead/128M${INTERNAL_PATH} --init_dummy_file=${INTERNAL_PATH} --input_file="/readahead/200M${INTERNAL_PATH} --iterations_per_loop=33 --learning_rate=0.0029293 --log_epsilon=-6 --master=${INTERNAL_PATH} --max_eval_steps=2 --max_predictions_per_seq=76 --max_seq_length=512 --model_dir=${INTERNAL_PATH} --num_eval_samples=10000 --num_tpu_cores=2048 --num_train_steps=700 --num_warmup_steps=0 --optimizer=lamb --norepeatable --replicas_per_host=4 --rpclog=-1 --save_checkpoints_steps=33 --sleep_after_init=500 --start_warmup_step=-700 --steps_per_update=1 --stop_steps=700 --stop_threshold=0.72 --train_batch_size=6144 --use_bfloat16_activation --use_bfloat16_all_reduce --use_tpu --weight_decay_rate=0.001 --xprof_port=14002; done