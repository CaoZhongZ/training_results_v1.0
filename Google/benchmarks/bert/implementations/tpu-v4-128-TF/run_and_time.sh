for i in {1..1}; do python3 run_pretraining.py --batch_size_buckets=58 --batch_size_buckets=30 --batch_size_buckets=16 --bert_config_file=${INTERNAL_PATH} --beta_1=0.9 --beta_2=0.999 --nobinarylog --${INTERNAL}_job_name=coordinator --${INTERNAL}_jobs="tpu_worker|${INTERNAL_PATH} --${INTERNAL}_num_eigen_threads=1 --${INTERNAL}_num_operation_threads=1 --${INTERNAL}_port=14001 --${INTERNAL}_rpc_layer=rpc2 --no${INTERNAL}_run_locally --${INTERNAL}_session_gc_seconds=86400 --${INTERNAL}_task=0 --census_cpu_accounting_enabled --noclip_by_global_norm_after_grad --nodo_eval --do_train --enable_profiling --eval_batch_size=3072 --eval_input_file="${INTERNAL_PATH} --gfs_user=tpu-perf-team --init_checkpoint=${INTERNAL_PATH} --init_dummy_file=${INTERNAL_PATH} --input_file="${INTERNAL_PATH} --iterations_per_loop=56 --learning_rate=0.0015 --log_epsilon=-6 --master=${INTERNAL_PATH} --max_eval_steps=4 --max_predictions_per_seq=76 --max_seq_length=512 --model_dir=${INTERNAL_PATH} --num_eval_samples=10000 --num_tpu_cores=128 --num_train_steps=1141 --num_warmup_steps=100 --optimizer=lamb --norepeatable --replicas_per_host=8 --rpclog=-1 --save_checkpoints_steps=56 --seq_len_buckets=128 --seq_len_buckets=256 --seq_len_buckets=512 --sleep_after_init=250 --start_warmup_step=0 --steps_per_update=1 --stop_steps=1141 --stop_threshold=0.72 --train_batch_size=3072 --use_bfloat16_activation --use_bfloat16_all_reduce --use_tpu --weight_decay_rate=0.01 --xprof_port=14002; done